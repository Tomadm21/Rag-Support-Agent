# Architecture Overview

## System Context (C4 Level 1)

The RAG Support Agent interacts with customers (via the UI) and uses OpenAI as an external LLM provider. Knowledge is stored in a Weaviate vector database.

```mermaid
C4Context
  title System Context Diagram - RAG Support Agent

  Person(user, "Support Agent", "Uses the system to generate and send ticket responses.")
  System(system, "RAG Support Agent", "Orchestrates multi-agent pipelines for automated support.")
  System_Ext(openai, "OpenAI API", "Provides LLM reasoning and embeddings.")
  System_Ext(weaviate, "Weaviate DB", "Stores and retrieves semantic document chunks.")

  Rel(user, system, "Inputs tickets, reviews drafts")
  Rel(system, openai, "LLM analysis & synthesis")
  Rel(system, weaviate, "Vector search")
```

## Container Architecture (C4 Level 2)

The system is composed of a React frontend and a FastAPI backend. The backend uses LangGraph to coordinate different specialist agents.

```mermaid
C4Container
  title Container Diagram - RAG Support Agent

  Container(ui, "Frontend App", "React, Tailwind", "Provides ticket interface and live preview.")
  Container(api, "Backend API", "FastAPI", "Serves endpoints and manages agent execution.")
  Container(graph, "Agent Orchestrator", "LangGraph", "Coordinates the stateful flow between agents.")
  ContainerDb(db, "Vector Store", "Weaviate", "Stores vectorized knowledge base.")

  Rel(ui, api, "REST / SSE", "JSON")
  Rel(api, graph, "Triggers workflow", "State Object")
  Rel(graph, db, "Semantic Search", "GraphQL/GRPC")
```

## Component Architecture (C4 Level 3)

The LangGraph "Agent Orchestrator" manages a linear pipeline of specialized nodes.

```mermaid
graph TB
  subgraph "Agent Pipeline"
    P[Parse Input] --> C[Classifier Agent]
    C --> R[Retriever Agent]
    R --> G[Generator Agent]
    G --> V[Validator Agent]
    V --> F[Format Response]
  end

  subgraph "External"
    LLM[OpenAI GPT-4]
    VDB[Weaviate]
  end

  C -.-> LLM
  R -.-> VDB
  G -.-> LLM
  V -.-> LLM
```

## Architectural Patterns

- **RAG (Retrieval-Augmented Generation)**: Leverages semantic search to give the LLM context-specific knowledge, reducing hallucinations.
- **Multi-Agent Orchestration**: Breaks down complex tasks into smaller, specialized steps (Classification -> Retrieval -> Generation).
- **Event-Driven UI Updates**: Uses Server-Sent Events (SSE) to stream long-running agent processes back to the client for a responsive feel.

## Key Design Decisions

1.  **LangGraph for State Management**: Chosen to handle the complex, multi-step nature of the agent pipeline with reproducible state and easier debugging.
2.  **Weaviate for Vector Search**: Provides high-performance semantic search with a flexible schema, ideal for evolving knowledge bases.
3.  **CopilotKit for Frontend AI**: Used to seamlessly integrate AI capabilities (like readable state and actions) into the React interface.
